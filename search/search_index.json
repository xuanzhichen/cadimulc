{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>CADIMULC is a light package standing for CAusal DIscovery  with Multiple Latent Confounders, providing easy-to-use Python APIs  to learn an empirical causal graph from generally raw data with relatively efficiency.</p>"},{"location":"#overview","title":"Overview","text":""},{"location":"#the-hybrid-methodology","title":"The Hybrid Methodology","text":"<p>Write down the descriptions here.</p>"},{"location":"#causal-discovery-workflow","title":"Causal Discovery Workflow","text":"<p>Write down the descriptions here.</p>"},{"location":"#modules-in-cadimulc","title":"Modules in Cadimulc","text":"<p>Write down the descriptions here.</p>"},{"location":"#citation","title":"Citation","text":"<p>Please cite the following paper(s) depending on which approach you use in your reports or publications: <pre><code>@article{chen2021causal,\n  title={Causal discovery in linear non-gaussian acyclic model with multiple latent confounders},\n  author={Chen, Wei and Cai, Ruichu and Zhang, Kun and Hao, Zhifeng},\n  journal={IEEE Transactions on Neural Networks and Learning Systems},\n  volume={33},\n  number={7},\n  pages={2816--2827},\n  year={2021},\n  publisher={IEEE}\n}\n</code></pre></p>"},{"location":"#reminder-and-news","title":"Reminder and News","text":"<p>February 19, 2024</p> <p>Maintenance and updates might not be timely since CADIMULC is personally developed without sponsors.  Xuanzhi Chen is sorry about that, but opening the issue and advancing the community are always welcomed. </p> <p>Reach Out: xuanzhichen.42@gmail.com</p>"},{"location":"#license","title":"License","text":"<p>Copyright (C) 2022-2024 Xuanzhi Chen (DMIR lab, Guangdong University of Technology, China)</p> <p>CADIMULC is downloaded for free, provided \"as is\" WITHOUT ANY EXPRESS OR IMPLIED WARRANTY; CADIMULC is developed in hope of being beneficial for empirical data analysis in causation, but WITHOUT WARRANTY OF ABSOLUTELY ACCURATE INTERPRETATION.</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>Xuanzhi Chen would like to thank the DMIR laboratory for offering him research opportunities,  with special thanks to Ruichu Cai (\u8521\u745e\u521d) of the lab director and Dongning Liu (\u5218\u51ac\u5b81) of the dean in School of Computer.</p> <p>Jie Qiao (\u4e54\u6770) and Zhiyi Huang (\u9ec4\u667a\u6bc5) were willing to spend their time in personal discussions with Xuanzhi Chen  about details in the paper; Zhengming Chen (\u9648\u6b63\u94ed) patiently helped point out initial mistakes in the paper; thanks to other graduate students, such as Zeqin Yang (\u6768\u6cfd\u52e4), Xiaokai Huang (\u9ec4\u6653\u6977), and Yu Xiang (\u5411\u5b87), for their generosity of teaching when Xuanzhi chen was initially building the repository.</p> <p>Finally, Xuanzhi Chen owes a great debt to his advisor Wei Chen (\u9648\u8587) for her encouragement  when Xuanzhi started studying causation two years ago \u2014 \"Do it, just have your own interest of research and your own rhythm of lifetime\".</p>"},{"location":"evaluation/","title":"Evaluation","text":"class: Evaluator  <p>Write down some descriptions here.</p> <ul> <li> <p>TP (True Positives): The number of the estimated directed pairs that   are consistent with the true causal pairs. Namely, TP qualifies the   correct estimation of (truly) causal relationships.</p> </li> <li> <p>FP (False Positives): The number of the estimated directed pairs that   do not present in the true causal pairs.</p> </li> <li> <p>TN: (True Negatives): The number of the unestimated directed pairs   that are consistent with the true causal pairs. Namely, TN reflects   the correct prediction of non-existential causal relationships.</p> </li> <li> <p>FN (False Negatives): The number of the unestimated directed pairs   that do present in the true causal pairs.</p> </li> </ul> <p>Example</p> <pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>  method: precision_pairwise  <p>Precision refers to the proportion of the correctly estimated directed pairs in all the estimated directed pairs. The higher the precision, the stronger the correct recognition among the individual causal pairs. (Precision = TP / (TP + FP) = TP / all estimated directed pairs)</p> Note <p>precision_pairwise() only focus on the assessment of directed pairs (not bi-directed pairs or undirected pairs.</p> <p>Parameters:</p> Name Type Description Default <code>true_graph</code> <code>ndarray</code> <p>Write down the descriptions.</p> required <code>est_graph</code> <code>ndarray</code> <p>Write down the descriptions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Write down the descriptions.</p> Source code in <code>cadimulc\\utils\\evaluation.py</code> <pre><code>@staticmethod\ndef precision_pairwise(true_graph: ndarray, est_graph: ndarray) -&gt; float:\n    \"\"\"\n    Precision refers to the proportion of the correctly estimated directed\n    pairs in all the estimated directed pairs.\n    The higher the precision, the stronger the correct recognition\n    among the individual causal pairs.\n    (Precision = TP / (TP + FP) = TP / all estimated directed pairs)\n\n    Note:\n        precision_pairwise() only focus on the assessment of\n        directed pairs (not bi-directed pairs or undirected pairs.\n\n    Parameters:\n        true_graph: Write down the descriptions.\n        est_graph: Write down the descriptions.\n\n    Returns:\n        Write down the descriptions.\n    \"\"\"\n\n    _, dict_directed_parent = Evaluator.get_pairwise_info(true_graph)\n    est_pairs = Evaluator.get_directed_pairs(est_graph)\n    num_est_pairs = len(est_pairs)\n\n    if num_est_pairs &gt; 0:\n        tp = 0\n\n        for est_pair in est_pairs:\n            child = est_pair[1]\n            parent = est_pair[0]\n\n            if parent in dict_directed_parent[child]:\n                tp += 1\n\n        precision = round((tp / num_est_pairs), 3)\n\n    else:\n        precision = float(0)\n\n    return precision\n</code></pre> <p>Tip</p> \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\]"},{"location":"hybrid_algorithms/","title":"Hybrid Algorithms","text":"Base Class: HybridFrameworkBase Method: _causal_skeleton_learning <p>Write down some descriptions here.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>ndarray</code> <p>Write down some descriptions here.</p> required <p>Returns:</p> Type Description <code>object</code> <p>Update <code>_skeleton</code>, <code>_adjacency_matrix</code>, and <code>_stage1_time</code></p> Source code in <code>cadimulc\\hybrid_algorithms\\hybrid_framework.py</code> <pre><code>def _causal_skeleton_learning(self, dataset: ndarray) -&gt; object:\n    \"\"\"\n    Write down some descriptions here.\n\n    &lt;!--\n    Arguments:\n        pc_alpha (parameter) : float\n            Write down some descriptions here.\n        _dataset (attribute) : ndarray\n            Write down some descriptions here.\n    --&gt;\n\n    Parameters:\n        dataset: Write down some descriptions here.\n\n    Returns:\n        Update ``_skeleton``, ``_adjacency_matrix``, and ``_stage1_time``\n    \"\"\"\n\n    self._dim = dataset.shape[1]\n    self._dataset = dataset\n\n    for i in range(self._dim):\n        self._parents_set[i] = set()\n\n    data = cp.copy(self._dataset)\n\n    # Notes for developer:\n    # Unify the linear independence test even for nonlinear-mlc.\n    skeleton, running_time = get_skeleton_from_pc(\n        data=data,\n        alpha=self.pc_alpha,\n        ind_test_type='linear'\n    )\n\n    self._skeleton = cp.copy(skeleton)\n    self._adjacency_matrix = cp.copy(skeleton)\n    self._stage1_time = running_time\n\n    return self\n</code></pre> Class: Nonlinear-MLC Method: fit <p>Fitting data via the Nonlinear-MLC causal discovery algorithm.</p> <p>The procedure comprises causal skeleton learning in the initial stage, and non-linear regression-independence-tests over maximal cliques for the subsequence. Notice that the maximal cliques are immediately recognized by the estimated skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>ndarray</code> <p>The observational dataset shown as a matrix or table, with a format of \"sample (n) * dimension (d).\" (input as Pandas dataframe is also acceptable)</p> required <p>Returns:</p> Name Type Description <code>self</code> <code>object</code> <p>Update the estimated causal graph represented as <code>adjacency_matrix</code>. The <code>adjacency_matrix</code> is a (d * d) numpy array with 0/1 elements characterizing the causal direction.</p> Source code in <code>cadimulc\\hybrid_algorithms\\hybrid_algorithms.py</code> <pre><code>def fit(self, dataset: ndarray) -&gt; object:\n    \"\"\"\n    Fitting data via the *Nonlinear-MLC* causal discovery algorithm.\n\n    The procedure comprises causal skeleton learning in the initial stage,\n    and non-linear regression-independence-tests over maximal cliques\n    for the subsequence. Notice that the maximal cliques are immediately\n    recognized by the estimated skeleton.\n\n    Parameters:\n        dataset:\n            The observational dataset shown as a matrix or table,\n            with a format of \"sample (n) * dimension (d).\"\n            (input as Pandas dataframe is also acceptable)\n\n    Returns:\n        self:\n            Update the estimated causal graph represented as ``adjacency_matrix``.\n            The ``adjacency_matrix`` is a (d * d) numpy array with 0/1 elements\n            characterizing the causal direction.\n    \"\"\"\n\n    start = time.perf_counter()\n\n    # Reconstruct a causal skeleton using the PC-stable algorithm.\n    self._skeleton = self._causal_skeleton_learning(dataset)\n\n    # Recognize the maximal-clique pattern based on the causal skeleton.\n    maximal_cliques = GraphPatternManager.recognize_maximal_cliques_pattern(\n        causal_skeleton=self._skeleton\n    )\n\n    # Initialize a graph pattern manager for subsequent learning.\n    graph_pattern_manager = GraphPatternManager(\n        init_graph=self._skeleton\n    )\n\n    # Perform the nonlinear-mlc causal discovery.\n    continue_search = True\n    while continue_search:\n\n        # Obtain the cliques that remain at least one edge undetermined.\n        undetermined_maximal_cliques = (\n            graph_pattern_manager.get_undetermined_cliques(maximal_cliques)\n        )\n\n        # End if all edges over the cliques have been determined.\n        if len(undetermined_maximal_cliques) == 0:\n            break\n\n        # Temporally store the adjacency matrix ahead of a search round.\n        graph_pattern_manager.store_last_managing_adjacency_matrix()\n\n        # In light of the L-ANMs theory (proposed in paper), start the search round\n        # by conducting non-linear causal inference based on maximal cliques.\n        determined_pairs = self._clique_based_causal_inference(\n            undetermined_maximal_cliques=undetermined_maximal_cliques\n        )\n\n        # Orient the determined causal directions\n        # after a search round over maximal cliques.\n        graph_pattern_manager.identify_directed_causal_pair(\n            determined_pairs=determined_pairs\n        )\n\n        # Update the causal adjacency matrix and parent-relations set\n        # after a search round over maximal cliques.\n        self._adjacency_matrix = (\n            graph_pattern_manager.managing_adjacency_matrix\n        )\n        self._parents_set = (\n            graph_pattern_manager.managing_parents_set\n        )\n\n        # Check if new causal relations have been determined\n        # after the last round searching.\n        newly_determined = (\n            graph_pattern_manager.check_newly_determined(\n                undetermined_maximal_cliques\n            )\n        )\n\n        # End if there is none of new causal relation advancing the further search.\n        if not newly_determined:\n            continue_search = False\n\n    end = time.perf_counter()\n\n    self._running_time += (end - start)\n\n    return self\n</code></pre> Method: _clique_based_causal_inference <p>For each of the undetermined maximal cliques (e.g. at least one edge within a maximal clique remains undirected) with respect to the whole maximal-clique patterns by the causal skeleton, the algorithm conducts non-linear regression with the explanatory variables selected from the undetermined maximal clique (See the \"Latent-ANMs Lemma\" in the relevant paper, Section 3), attempting to infer causal directions by regressing residuals and further independence tests.</p> Note <p>This method refers to a technical procedure inside the Nonlinear-MLC algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>undetermined_maximal_cliques</code> <code>list[list]</code> <p>A list of undetermined maximal cliques in which the element (maximal clique) involves at least one edge remaining undirected (e.g. [[X, Y, Z]] stands for the only one maximal clique  in the list). required <p>Returns:</p> Type Description <code>list</code> <p>The list of determined pairs over the inputting undetermined cliques after searching. (e.g. [[X, Y], [Y, Z]] stands for two of the determined pairs \"X -&gt; Y\" and \"Y -&gt; Z\").</p> Source code in <code>cadimulc\\hybrid_algorithms\\hybrid_algorithms.py</code> <pre><code>def _clique_based_causal_inference(\n        self,\n        undetermined_maximal_cliques: list[list]\n) -&gt; list:\n    \"\"\"\n    For each of the undetermined maximal cliques (e.g. at least one edge\n    within a maximal clique remains undirected) with respect to the whole\n    maximal-clique patterns by the causal skeleton,\n    the algorithm conducts non-linear regression with the explanatory variables\n    selected from the undetermined maximal clique (See the \"*Latent-ANMs* Lemma\"\n    in the relevant paper, Section 3),\n    attempting to infer causal directions by regressing residuals and\n    further independence tests.\n\n    Note:\n        This method refers to a technical procedure\n        inside the *Nonlinear-MLC* algorithm.\n\n    &lt;!--\n    Arguments for Testing:\n        _adjacency_matrix (attribute): ndarray\n        _dataset (attribute): ndarray\n    --&gt;\n\n    Parameters:\n        undetermined_maximal_cliques:\n            A list of undetermined maximal cliques in which the element\n            (maximal clique) involves at least one edge remaining undirected\n            (e.g. [[X, Y, Z]] stands for the only one maximal clique\n            &lt;X, Y, Z&gt; in the list).\n\n    Returns:\n        The list of determined pairs over the inputting undetermined cliques\n         after searching.\n         (e.g. [[X, Y], [Y, Z]] stands for two of the determined pairs\n         \"X -&gt; Y\" and \"Y -&gt; Z\").\n    \"\"\"\n\n    determined_pairs = []\n\n    # Conduct non-linear causal inference based on each maximal clique unit.\n    for undetermined_maximal_clique in undetermined_maximal_cliques:\n\n        # Initialize the lists with elements of undetermined causal relations.\n        # e.g. the element (cause, effect) specifies \"cause -&gt; effect\"\n        undetermined_pairs = []\n\n        # Get undetermined pairs within a clique.\n        for i in undetermined_maximal_clique:\n            for j in undetermined_maximal_clique[\n                undetermined_maximal_clique.index(i) + 1:\n            ]:\n                if (self._adjacency_matrix[i][j] == 1) and (\n                    self._adjacency_matrix[j][i] == 1\n                ):\n                    undetermined_pairs.append([i, j])\n\n        # Conduct pairwise non-linear regression and independence tests.\n        for pair in undetermined_pairs:\n            determined = False\n\n            p_value_max = self.pc_alpha\n            causation = copy_and_rename(pair)\n\n            # Unravel the pairwise inferred directions respectively.\n            pair_temp = cp.copy(pair)\n            pair_temp.reverse()\n            pair_reversed = copy_and_rename(pair_temp)\n\n            for cause, effect in zip(pair, pair_reversed):\n\n                # ========== Empirical Regressor Construction ==========\n\n                # initialization of explanatory-and-explained variables\n                explanatory_vars = set()\n                explained_var = set()\n\n                # basic explanatory-and-explained variables: cause-effect\n                explanatory_vars.add(cause)\n                explained_var.add(effect)  # namely the effect variable\n\n                # Add explanatory variables to strengthen empirical regression:\n\n                # determined parent-relations amidst the algorithm memory\n                explanatory_vars = explanatory_vars | set(self._parents_set[effect])\n\n                # undetermined connections within the maximal clique\n                explanatory_vars = explanatory_vars | (\n                        set(undetermined_maximal_clique) - {effect}\n                )\n\n                # Regress the effect variable on empirical explanatory variables\n                # (in an attempt to cancel unobserved confounding).\n\n                explanatory_data = cp.copy(\n                    self._dataset[:, list(explanatory_vars)]\n                )\n\n                # namely the data with respect to the effect variable\n                explained_data = cp.copy(\n                    self._dataset[:, list(explained_var)]\n                )\n\n                # regressing residuals via fitting SCMs\n                residuals = get_residuals_scm(\n                    explanatory_data=explanatory_data,\n                    explained_data=explained_data,\n                    regressor=self.regressor\n                )\n\n                # Remove effects of parent-relations from the cause variable\n                # (in an attempt to cancel unobserved confounding).\n\n                cause_parents = list(self._parents_set[cause])\n\n                if len(cause_parents) &gt; 0:\n                    cause_data = get_residuals_scm(\n                        explanatory_data=self._dataset[:, cause_parents],\n                        explained_data=self._dataset[:, cause],\n                        regressor=self.regressor\n                    )\n                else:\n                    cause_data = cp.copy(self._dataset[:, cause])\n\n                # ================== Independence Test =================\n\n                # Conduct the independence test\n                # between the cause variable and regressing residuals.\n                p_value = conduct_ind_test(\n                    explanatory_data=cause_data,\n                    residuals=residuals,\n                    ind_test_method=self.ind_test\n                )\n\n                # One single inferred causal direction is determined given the\n                # maximal p-value exceeding the threshold of the significant level.\n                if p_value &gt; p_value_max:\n                    determined = True\n\n                    p_value_max = p_value\n                    causation = (cause, effect)\n\n            if determined:\n                determined_pairs.append(causation)\n\n        return determined_pairs\n</code></pre>"},{"location":"hybrid_algorithms/#cadimulc.hybrid_algorithms.hybrid_framework.HybridFrameworkBase","title":"<code>cadimulc.hybrid_algorithms.hybrid_framework.HybridFrameworkBase</code>","text":"<p>A hybrid causal discovery framework with established implementations of discovering causal skeleton by Peter-Clark algorithm. The framework is incorporated into the initial stage of both Nonlinear-MLC and MLC-LiNGAM causal discovery algorithms.</p>"},{"location":"hybrid_algorithms/#cadimulc.hybrid_algorithms.hybrid_framework.HybridFrameworkBase.__init__","title":"<code>__init__(pc_alpha=0.5, _dataset=None, _dim=None, _skeleton=None, _adjacency_matrix=None, _parents_set={}, _running_time=0.0)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>pc_alpha</code> <code>float</code> <p>float (default: 0.5) Write down some descriptions here.</p> <code>0.5</code> <code>_dataset</code> <code>ndarray</code> <p>dataframe Write down some descriptions here.</p> <code>None</code> <code>_dim</code> <code>int</code> <p>int Write down some descriptions here.</p> <code>None</code> <code>_skeleton</code> <code>ndarray</code> <p>ndarray Write down some descriptions here.</p> <code>None</code> <code>_adjacency_matrix</code> <code>ndarray</code> <p>ndarray Write down some descriptions here.</p> <code>None</code> <code>_parents_set</code> <code>dict</code> <p>dict Write down some descriptions here.</p> <code>{}</code>"},{"location":"hybrid_algorithms/#cadimulc.hybrid_algorithms.hybrid_algorithms.NonlinearMLC","title":"<code>cadimulc.hybrid_algorithms.hybrid_algorithms.NonlinearMLC</code>","text":"<p>             Bases: <code>HybridFrameworkBase</code></p> <p>The hybrid algorithm Nonlinear-MLC, incorporation of the constraint-based and functional-based causal discovery methodology, is developed for causal inference on the general non-linear data (in presence of unknown factors).</p> Note <p>A primary feature of Nonlinear-MLC lies in exploiting the empirical non-linear causal inference strategies in light of the \"maximal-clique\" graphical pattern.</p>"},{"location":"hybrid_algorithms/#cadimulc.hybrid_algorithms.hybrid_algorithms.NonlinearMLC.__init__","title":"<code>__init__(regressor=LinearGAM(), ind_test='kernel_hsic', pc_alpha=0.05)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>regressor</code> <code>object</code> <p>Built-in regressor modules are recommended: <code>from pygam import LinearGAM</code> or <code>from sklearn.neural_network import MLPRegressor</code></p> <code>LinearGAM()</code> <code>ind_test</code> <code>str</code> <p>Popular independence tests methods are recommended: Kernel-based Conditional Independence tests (KCI); Hilbert-Schmidt Independence Criterion (HSIC) for General Additive Models (GAMs).</p> <code>'kernel_hsic'</code> <code>pc_alpha</code> <code>float</code> <p>Significance level of independence tests (p_value)</p> <code>0.05</code>"},{"location":"hybrid_algorithms/#reference","title":"Reference","text":"<ul> <li>Chen, XZ.*, Chen, W.*, Cai, RC. Non-linear Causal Discovery for Additive Noise Model with     Multiple Latent Confounders. Xuanzhi's Personal Website. 2023.</li> </ul>"},{"location":"hybrid_algorithms/#test","title":"Test","text":""},{"location":"hybrid_algorithms/#test2","title":"Test2","text":""},{"location":"quick_tutorials/","title":"Quick Tutorials","text":"<p>Hybrid Causal Discovery Workflow...</p>"},{"location":"quick_tutorials/#1-install","title":"1. Install","text":"<p>Write down the descriptions here.</p>"},{"location":"quick_tutorials/#2-generation","title":"2. Generation","text":"<p>Write down the descriptions here.</p>"},{"location":"quick_tutorials/#3-causal-discovery","title":"3. Causal Discovery","text":"<p>Write down the descriptions here.</p>"},{"location":"quick_tutorials/#4-evaluation","title":"4. Evaluation","text":"<p>Write down the descriptions here.</p>"}]}